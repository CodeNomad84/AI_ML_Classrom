{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5f4ad-4a6e-4ca4-8b08-bcf97f1e622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# بخش اول: مدلسازی پرسپترون صرفا با numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cc870f-7091-486a-9a87-9405b5a56423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perceptron.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_prepare_numpy(csv_path):\n",
    "    \"\"\"\n",
    "    Load the house price dataset, standardize features and\n",
    "    convert continuous price to binary labels (-1, +1).\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # select feature columns\n",
    "    feature_cols = ['Square_Footage', 'Num_Bedrooms', 'Num_Bathrooms',\n",
    "                    'Year_Built', 'Lot_Size', 'Garage_Size', 'Neighborhood_Quality']\n",
    "    X = df[feature_cols].values.astype(np.float32)\n",
    "    # standardize features (zero mean, unit variance)\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    # convert price to binary labels: above-mean => +1, else -1\n",
    "    prices = df['House_Price'].values\n",
    "    mean_price = prices.mean()\n",
    "    y = np.where(prices > mean_price, 1, -1).astype(np.int32)\n",
    "    # split into train and test\n",
    "    return train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "def perceptron_train_numpy(X_train, y_train, lr=0.01, epochs=50):\n",
    "    \"\"\"\n",
    "    Train a perceptron using the classic update rule.\n",
    "    Returns weight vector w and bias b.\n",
    "    \"\"\"\n",
    "    n_features = X_train.shape[1]\n",
    "    # initialize weights and bias to zero\n",
    "    w = np.zeros(n_features, dtype=np.float32)\n",
    "    b = 0.0\n",
    "    # training loop\n",
    "    for epoch in range(epochs):\n",
    "        for xi, yi in zip(X_train, y_train):\n",
    "            # compute the linear output\n",
    "            activation = np.dot(w, xi) + b\n",
    "            # perceptron prediction (+1 or -1)\n",
    "            y_pred = 1 if activation >= 0 else -1\n",
    "            # update only if misclassified\n",
    "            if yi * activation <= 0:\n",
    "                w += lr * yi * xi\n",
    "                b += lr * yi\n",
    "    return w, b\n",
    "\n",
    "def perceptron_predict_numpy(X, w, b):\n",
    "    \"\"\"\n",
    "    Predict class labels for X using learned w and b.\n",
    "    \"\"\"\n",
    "    activations = X.dot(w) + b\n",
    "    return np.where(activations >= 0, 1, -1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_numpy('house_price_regression_dataset.csv')\n",
    "    # train\n",
    "    w, b = perceptron_train_numpy(X_train, y_train, lr=0.01, epochs=100)\n",
    "    # predict and evaluate\n",
    "    y_pred = perceptron_predict_numpy(X_test, w, b)\n",
    "    acc = np.mean(y_pred == y_test)\n",
    "    print(f\"Numpy Perceptron accuracy: {acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a39e17c-252e-41bc-b7ed-273a0de4e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) پیاده‌سازی پرسپترون با sklearn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "351a42df-c539-4e7e-8b6f-9ddc91114691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn Perceptron accuracy: 0.9733\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_and_prepare_sklearn(csv_path):\n",
    "    \"\"\"\n",
    "    Load dataset, split into train/test, and standardize features.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    feature_cols = ['Square_Footage', 'Num_Bedrooms', 'Num_Bathrooms',\n",
    "                    'Year_Built', 'Lot_Size', 'Garage_Size', 'Neighborhood_Quality']\n",
    "    X = df[feature_cols].values\n",
    "    prices = df['House_Price'].values\n",
    "    # binary labels: price above mean => +1, else -1\n",
    "    y = (prices > prices.mean()).astype(int) * 2 - 1  # map to -1, +1\n",
    "    # split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)\n",
    "    # standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def run_sklearn_perceptron(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Train sklearn's Perceptron and evaluate accuracy.\n",
    "    \"\"\"\n",
    "    clf = Perceptron(max_iter=1000, eta0=0.01, tol=1e-3, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"sklearn Perceptron accuracy: {acc:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_sklearn('house_price_regression_dataset.csv')\n",
    "    run_sklearn_perceptron(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb20bd-4b17-4c1d-a641-fa27bb8e3696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) پیاده‌سازی پرسپترون با PyTorch  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e674f03b-1a3d-45b5-8f55-339c7a45b467",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\Meysam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:281\u001b[0m\n\u001b[0;32m    277\u001b[0m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    279\u001b[0m         kernel32\u001b[38;5;241m.\u001b[39mSetErrorMode(prev_error_mode)\n\u001b[1;32m--> 281\u001b[0m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# Libraries can either be in\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;66;03m# path/nvidia/lib_folder/lib or\u001b[39;00m\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;66;03m# path/nvidia/cuXX/lib (since CUDA 13.0) or\u001b[39;00m\n\u001b[0;32m    289\u001b[0m     \u001b[38;5;66;03m# path/lib_folder/lib\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:264\u001b[0m, in \u001b[0;36m_load_dll_libraries\u001b[1;34m()\u001b[0m\n\u001b[0;32m    260\u001b[0m     err \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mWinError(last_error)\n\u001b[0;32m    261\u001b[0m     err\u001b[38;5;241m.\u001b[39mstrerror \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    262\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdll\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or one of its dependencies.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    263\u001b[0m     )\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    266\u001b[0m     is_loaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: [WinError 1114] A dynamic link library (DLL) initialization routine failed. Error loading \"C:\\Users\\Meysam\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\lib\\c10.dll\" or one of its dependencies."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_and_prepare_torch(csv_path, device='cpu'):\n",
    "    \"\"\"\n",
    "    Load dataset, standardize features, convert to torch tensors.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    feature_cols = ['Square_Footage', 'Num_Bedrooms', 'Num_Bathrooms',\n",
    "                    'Year_Built', 'Lot_Size', 'Garage_Size', 'Neighborhood_Quality']\n",
    "    X = df[feature_cols].values.astype('float32')\n",
    "    # standardize in numpy then convert\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "    prices = df['House_Price'].values\n",
    "    y = np.where(prices > prices.mean(), 1, -1).astype('int64')\n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.3, random_state=42)\n",
    "    # convert to torch\n",
    "    X_train = torch.from_numpy(X_train).to(device)\n",
    "    X_test = torch.from_numpy(X_test).to(device)\n",
    "    y_train = torch.from_numpy(y_train).to(device)\n",
    "    y_test = torch.from_numpy(y_test).to(device)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def perceptron_train_torch(X_train, y_train, lr=0.01, epochs=10):\n",
    "    \"\"\"\n",
    "    Train perceptron manually using torch tensors.\n",
    "    Returns weight vector w and bias b.\n",
    "    \"\"\"\n",
    "    n_features = X_train.shape[1]\n",
    "    # initialize parameters\n",
    "    w = torch.zeros(n_features, dtype=torch.float32)\n",
    "    b = torch.zeros(1, dtype=torch.float32)\n",
    "    for epoch in range(epochs):\n",
    "        for xi, yi in zip(X_train, y_train):\n",
    "            # linear output\n",
    "            output = torch.dot(w, xi) + b\n",
    "            # prediction using sign\n",
    "            y_pred = 1 if output.item() >= 0 else -1\n",
    "            # update if wrong\n",
    "            if yi.item() * output.item() <= 0:\n",
    "                update = lr * yi.item()\n",
    "                w += update * xi\n",
    "                b += update\n",
    "    return w, b\n",
    "\n",
    "def perceptron_predict_torch(X, w, b):\n",
    "    \"\"\"\n",
    "    Predict class labels for X using learned w and b.\n",
    "    \"\"\"\n",
    "    outputs = X.matmul(w) + b\n",
    "    return torch.where(outputs >= 0, 1, -1)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import numpy as np\n",
    "    # load data\n",
    "    X_train, X_test, y_train, y_test = load_and_prepare_torch(\n",
    "        'house_price_regression_dataset.csv', device='cpu')\n",
    "    # train\n",
    "    w, b = perceptron_train_torch(X_train, y_train, lr=0.01, epochs=50)\n",
    "    # predict and evaluate\n",
    "    y_pred = perceptron_predict_torch(X_test, w, b)\n",
    "    acc = (y_pred == y_test).float().mean().item()\n",
    "    print(f\"PyTorch Perceptron accuracy: {acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
